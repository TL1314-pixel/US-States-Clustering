---
title: "finalcode_eda+kmeans"
format: html
execute:
  echo: true
  warning: false
  message: false
editor: visual
fig-width: 6
fig-asp: 0.618
fig-align: center
out-width: "70%"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## EDA

### preparing

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(ggplot2)
library(reshape2)
library(corrplot)
library(viridis)
library(gridExtra)
library(usmap)
library(dplyr)
library(tidyr)
library(knitr)
library(kableExtra)

df <- read.csv("FinalData.csv")

# import dataset+log transform
df <- df %>%
  mutate(TotPop_log = log10(TotPop))
str(df)
```

Because the population span is relatively large, we use log to reduce the gap for easier visualization.

### Data range+check for missing value

```{r}
# check the missing value
colSums(is.na(df))
```

there is a mssing value for TotPop_log

```{r}
# remove the row that contains missing value (Puerto Rico)
df <- na.omit(df)
```

```{r}
# summary statistic table for the 10 social factors
tbl <-
  df %>%
  select(AgingPer, PovPer, DisPer, UnempPer, HICPer, 
         PSEPer, MGR, WhitePer, MHI, TotPop_log) %>%
  summarise(
    across(
      everything(),
      list(
        mean   = ~ mean(.x, na.rm = TRUE),
        sd     = ~ sd(.x, na.rm = TRUE),
        min    = ~ min(.x, na.rm = TRUE),
        q1     = ~ quantile(.x, 0.25, na.rm = TRUE),
        median = ~ median(.x, na.rm = TRUE),
        q3     = ~ quantile(.x, 0.75, na.rm = TRUE),
        max    = ~ max(.x, na.rm = TRUE)
      )
    )
  ) %>%
  pivot_longer(
    everything(),
    names_to      = c("variable", ".value"),
    names_pattern = "^(.*)_(.*)$" ) 

tbl %>%
  kable(caption = "Summary statistics for 10 Social Factors", digits = 2) %>%
  kable_styling(
    # add lines to the table
    bootstrap_options = c("striped", "bordered"),  
    full_width = FALSE,
    position = "center"
  )

```

### Variable Distribution

1.  **Boxplots for each indicator**

```{r warning=FALSE}
df_long <- df %>%
  select(AgingPer, PovPer, DisPer, UnempPer, HICPer,
         PSEPer, MGR, WhitePer, MHI, TotPop_log) %>%
  pivot_longer(everything(), names_to = "Variable", values_to = "Value")

ggplot(df_long, aes(x = Variable, y = Value)) +
  geom_boxplot(fill = "#69b3a2", outlier.color = "red") +
  facet_wrap(~ Variable, scales = "free") + 
  theme_minimal(base_size = 10) +
  theme(
    strip.text = element_text(face = "bold", size = 15),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.title = element_blank()
  ) +
  labs(title = "Boxplots of 10 Healthcare Vulnerability Social Factors")
```

2.  Histogram + Normality Curve + QQ-plot

    ```{r}
    # histogram and normality curve for each factor
    vars <- c("AgingPer","PovPer","DisPer","UnempPer","HICPer",
              "PSEPer","MGR","WhitePer","MHI","TotPop_log")

    plot_list <- lapply(vars, function(v){
      ggplot(df, aes_string(x = v)) +
    geom_histogram(aes(y = ..density..),
                   bins = 20, fill = "#9ecae1", color = "white") +
    stat_function(fun = dnorm,
                  args = list(mean = mean(df[[v]], na.rm = TRUE),
                              sd = sd(df[[v]], na.rm = TRUE)),
                  color = "red", size = 1) +
    theme_minimal(base_size = 15) +
    labs(title = paste("Histogram of", v), x = v, y = "Density")})

    # create 10 plots on one image, use in the report 
    # do.call(grid.arrange, c(plot_list, ncol = 3))

    for (i in seq(1, length(plot_list), by = 2)) {
      grid.arrange(plot_list[[i]],
               plot_list[[i+1]],
               ncol = 2)}

    # QQ-plot for each factor
    vars <- c("AgingPer","PovPer","DisPer","UnempPer","HICPer",
          "PSEPer","MGR","WhitePer","MHI","TotPop_log")

    qq_list <- lapply(vars, function(v){
      ggplot(df, aes_string(sample = v)) +
    stat_qq() +
    stat_qq_line(color = "red") +
    theme_minimal(base_size = 12) +
    labs(
      title = paste("Normal Q-Q Plot of", v),
      x = "Theoretical Quantiles",
      y = "Sample Quantiles"
    )
    })

    # create 10 plots on one image, use in the report 
    # do.call(grid.arrange, c(qq_list, ncol = 3))

    for (i in seq(1, length(qq_list), by = 2)) {
      if (i == length(qq_list)) {
    grid.arrange(qq_list[[i]], ncol = 1)
      } else {
    grid.arrange(qq_list[[i]], qq_list[[i + 1]], ncol = 2)
      }
    }

    ```

3.  outlier

    ```{r}
    # Outlier Detection (IQR method)

    # Function to detect outliers using IQR
    find_outliers <- function(x){
      Q1 <- quantile(x, 0.25, na.rm = TRUE)
      Q3 <- quantile(x, 0.75, na.rm = TRUE)
      IQR <- Q3 - Q1
      lower <- Q1 - 1.5 * IQR
      upper <- Q3 + 1.5 * IQR
      return(x < lower | x > upper)}

    # Apply function and attach state names
    outlier_results <- lapply(vars, function(var){
      mask <- find_outliers(df[[var]])
      # return outlier states
      df$NAME[mask]})

    names(outlier_results) <- vars
    outlier_results
    ```

4.  heatmap

```{r}
vuln_vars <- df %>%
      select(AgingPer, PovPer, DisPer, UnempPer, HICPer,
             PSEPer, MGR, WhitePer, MHI, TotPop_log)

corr_matrix <- round(cor(vuln_vars), 2)

# create the heatmap
corr_melt <- melt(corr_matrix)
corr_melt_upper <- corr_melt %>% 
  filter(as.numeric(Var1) < as.numeric(Var2))
ggplot(corr_melt_upper, aes(Var1, Var2, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_viridis(option = "plasma", limits=c(-1,1), name = "Correlation") +
  geom_text(aes(label = value), color = "white", size = 4) +
  theme_minimal(base_size = 14) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title = element_blank(),
        panel.grid = element_blank()) +
      labs(title = "Correlation Heatmap (Upper Triangle Only)")
```

5.  Geographic Representation (Map)

```{r}
df_map <- df %>% rename(state = NAME)

# Aging Rate 
plot_usmap(data = df_map, values = "AgingPer", color = "white") +
  scale_fill_viridis(option = "plasma", name = "% Age 65+") +
  labs(title = "Aging Population (%) by State") +
  theme(legend.position = "right")
```

```{r}
# Poverty Rate
plot_usmap(data = df_map, values = "PovPer", color = "white") +
  scale_fill_viridis(option = "plasma", name = "Poverty (%)") +
  labs(title = "Poverty Rate by State") +
  theme(legend.position = "right")
```

```{r}
# Disability Rate 
plot_usmap(data = df_map, values = "DisPer", color = "white") +
  scale_fill_viridis(option = "plasma", name = "Disability (%)") +
  labs(title = "Disability Rate by State")
```

```{r}
# Post-Secondary Education Attainment Rate
plot_usmap(data = df_map, values = "PSEPer", color = "white") +
  scale_fill_viridis(option = "plasma", name = "% Post-Secondary") +
  labs(title = "Post-Secondary Education Attainment Rate by State")
```

```{r}
# Median Annual Household Income 
plot_usmap(data = df_map, values = "MHI", color = "white") +
  scale_fill_viridis(option = "plasma", name = "Income per $1,000 ($)") +
  labs(title = "Median Household Income by State") +
  theme(legend.position = "right")
```

```{r}
# Health Insurance Coverage Rate 
plot_usmap(data = df_map, values = "HICPer", color = "white") +
  scale_fill_viridis(option = "plasma", name = "% Insured") +
  labs(title = "Health Insurance Coverage by State")
```

## Unsupervised Learning

### preparing

```{r}
library(tidyverse)
library(sf)
library(spData)
library(dplyr)
library(ggplot2)
library(tmap)
library(clValid)
library(mclust)
library(NbClust)

data(us_states)

hlth  <- read.csv("FinalData.csv")
rownames(hlth) <- hlth$NAME
# drop Puerto Rico
hlth <- hlth %>% filter(NAME != "Puerto Rico")
```

```{r}
# to minimize the difference, we log-transformed the total population
hlth_clean <- hlth %>%
  mutate(logPop = log(TotPop)) %>%
  select(logPop, AgingPer, PovPer, DisPer, UnempPer,
         HICPer, PSEPer, MGR, WhitePer, MHI)
```

```{r}
# Scale the data
Xsc <- scale(hlth_clean)
```

K-means showed stronger stability on AD, FOM. Therefore, we chose k-means for final modeling.

```{r}
# choose the number of clusters

# combine three plots into one image for better presentation
# par(mfrow = c(1, 3), 
    # cex.main = 2,         
    # cex.lab  = 1.5,        
    # cex.axis = 1.5)

# Elbow plot
Ks <- 1:10
wcss <- numeric(length(Ks))
for (k in Ks) {
  km <- kmeans(Xsc, centers = k, nstart = 50, iter.max = 100)
  wcss[k] <- km$tot.withinss
  }
plot(Ks, wcss, type = "b", pch = 19,
     xlab = "K (clusters)", ylab = "Total within-cluster SS (WCSS)",
     main = "Elbow Plot")

# # set seed for reproducibility
set.seed(1314)

# compute the gap statistic
gap <- clusGap(Xsc, FUN = kmeans, K.max = 10, B = 100, 
               nstart = 50, iter.max = 100)

# plot the statistic 
plot(gap, main = "Gap statistic", xlab = "K (clusters)")

# Fit final k-means at chosen K and visualize in first two PCs
Kstar <- maxSE(gap$Tab[, "gap"], gap$Tab[, "SE.sim"], 
               method = "Tibs2001SEmax")
Kstar

# Silhouette method
Ks2 <- 2:10
avg_sil <- numeric(length(Ks2))
dmat <- dist(Xsc, method = "euclidean")

# compute Silhouette method 
for (i in seq_along(Ks2)) {
  k <- Ks2[i]
  km <- kmeans(Xsc, centers = k, nstart = 50, iter.max = 100)
  sil <- silhouette(km$cluster, dmat)
  avg_sil[i] <- mean(sil[, "sil_width"])
}

# plot the method 
plot(Ks2, avg_sil, type = "b", pch = 19, 
     xlab = "K (clusters)", ylab = "Average silhouette width", 
     main = "Silhouette Diagnostic")

# find the max average silhouette width 
Ks2[which.max(avg_sil)]
```

Based on the result, elbow plot and silhouette diagnostic suggest 3 clusters, while gap statistic suggests 4 clusters is optimal. Since 3 clusters is an elbow point on the elbow plot (measures within-cluster variation), where WCSS is explained less after 3 clusters comparing to the clusters before and including 2. In addition, silhouette diagnostic (measures the separation between clusters) suggests that 3 clusters maximizes the average silhouette width, which has high average dissimilarity of each observation to points in the nearest neighboring cluster. Whereas for gap statistic, the gap at 4 clusters between the observed WCSS and its expectation under a reference (null) distribution with no clustering is sufficient enough to show that there is clustering structure. Overall, clusters k = 3 is optimal since 2 out of 3 methods suggest 3 clusters, and 3 clusters is easier to obtain interpretable and meaningful cluster structures.

```{r}
# Compare clustering algorithms in R at k = 3
clmethods <- c("hierarchical","kmeans","model")
stab <- clValid(Xsc, nClust = 3, clMethods = clmethods, validation = "stability")
optimalScores(stab) %>%
  kable(caption = "comparing clustering algorithms by Stability measures at k = 3", 
        digits = 2) %>%
  kable_styling(
    # add lines to the table
    bootstrap_options = c("striped", "bordered"),  
    full_width = FALSE,
    position = "center"
  )
```

Based on the result of cluster stability, average proportion of non-overlap (APN) measures the average proportion of observations not placed in the same cluster by clustering based on the full data and the data with one column removed. The average distance (AD) measures the average distance between observations placed in the same cluster under both cases. The average distance between means (ADM) measures the average distance between cluster centers for observations placed in the same cluster under both cases. The figure of merit (FOM) measures the average intra-cluster variance of the deleted column, where the clustering is based on the undeleted columns. AD and FOM suggest that k-means algorithms has the optimal value at the given 3 clusters, while APN and ADM suggest hierarchical method. However, since the study aims to partition states into 3 clusters with similar healthcare vulnerability profiles, this aligns with k-means algorithms where number of clusters are predetermined. Moreover, since all 10 variables are continuous social factors, and k-means choose clusters based on its centroid which is the mean value of each variable, this helps using the characteristics of each states in the interpretation.

```{r}
# Using 3 clusters
k_means_results <- kmeans(Xsc, centers = 3, nstart = 50)
hlth_clean <- hlth_clean %>% mutate(cluster = k_means_results$cluster)
cluster_states <- split(hlth$NAME, hlth_clean$cluster)

#table of centers
cluster_center <- as.data.frame(k_means_results$centers)
cluster_center$Cluster <- paste0(rownames(cluster_center))
cluster_center <- cluster_center %>% select(Cluster, everything())
knitr::kable(cluster_center, digits = 3, caption = "Cluster Centers for K-means (k = 3)")

# table of states
cluster_state <- data.frame(
  Cluster = paste0("Cluster ", names(cluster_states)),
  States  = sapply(cluster_states, function(x) paste(x, collapse = ", "))
)

knitr::kable(cluster_state,
      caption = "States Belonging to Each Cluster",
      longtable = TRUE) 
```

```{r}
set.seed(1314)

# Spatial Data Visualization
hlth$cluster <- factor(k_means_results$cluster)
us_map <- us_states %>%
  left_join(hlth, by = "NAME")
ggplot(us_map) +
  geom_sf(aes(fill = cluster), color = "white", size = 0.2) +
  scale_fill_brewer(palette = "YlGnBu", name = "Cluster") +
  labs(
    title = "K-means Clustering of U.S. States (k = 3)"
  ) +
  theme_minimal()
```
